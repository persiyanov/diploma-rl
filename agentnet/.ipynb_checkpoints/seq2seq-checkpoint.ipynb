{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne.layers import *\n",
    "import lasagne\n",
    "import numpy as np\n",
    "\n",
    "n_tokens=10000\n",
    "\n",
    "PAD_TOKEN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class encoder:\n",
    "    \n",
    "    input_phrase = T.imatrix('input_phrase')\n",
    "    mask = T.neq(input_phrase, PAD_TOKEN)\n",
    "    l_in = InputLayer((None,None),input_phrase,name='prev phrase input')\n",
    "    l_mask = InputLayer((None, None), mask, name='mask input')\n",
    "    l_emb = EmbeddingLayer(l_in,n_tokens,128, name=\"prev phrase embedding\")\n",
    "    \n",
    "    l_gru0 = GRULayer(l_emb,\n",
    "                      128,\n",
    "                      name='gru0',\n",
    "                      grad_clipping=1,\n",
    "                      mask_input=l_mask,\n",
    "                      only_return_final=True)\n",
    "    l_output=l_gru0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll = get_output(encoder.l_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = theano.function([encoder.input_phrase], ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oo = output(np.array([[1,2,3,0,0,0]], dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(oo[0][1], oo[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(oo[0][2], oo[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.memory import GRUCell\n",
    "from agentnet.resolver import ProbabilisticResolver\n",
    "\n",
    "class decoder:\n",
    "    l_prev_token = InputLayer((None,),name='prev token',input_var=T.ivector())\n",
    "    \n",
    "    l_prev_emb = EmbeddingLayer(l_prev_token,n_tokens,128)\n",
    "    \n",
    "    l_prev_gru = InputLayer((None,128),name='prev gru state')\n",
    "    l_gru = GRUCell(l_prev_gru,l_prev_emb)\n",
    "    \n",
    "    \n",
    "    token_probas_bottleck = DenseLayer(l_gru,256,nonlinearity=lasagne.nonlinearities.tanh)\n",
    "    token_probas = DenseLayer(token_probas_bottleck,n_tokens,\n",
    "                              nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    \n",
    "    next_token_generated = ProbabilisticResolver(token_probas)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 128), (None, 128))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.l_gru.output_shape, encoder.l_output.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Recurrence\n",
    "from collections import OrderedDict\n",
    "\n",
    "BOS_token = 1\n",
    "class generative_recurrence:\n",
    "    \n",
    "    state = OrderedDict({decoder.l_gru: decoder.l_prev_gru, \n",
    "             decoder.next_token_generated : decoder.l_prev_token})\n",
    "    \n",
    "    n_steps = theano.shared(10,name=\"generative n_steps\")\n",
    "    \n",
    "    \n",
    "    recurrence = Recurrence(state_variables=state, \n",
    "                            state_init={decoder.l_gru:encoder.l_output},\n",
    "                            unroll_scan=False,\n",
    "                            tracked_outputs = [decoder.next_token_generated,decoder.token_probas],\n",
    "                            n_steps=n_steps)\n",
    "    \n",
    "    _, (generated_tokens, token_probas) = recurrence.get_sequence_layers()\n",
    "    \n",
    "    output_seq, prob_seq = get_output([generated_tokens,token_probas])\n",
    "    \n",
    "    apply_fun = theano.function([encoder.input_phrase],output_seq,\n",
    "                                 updates=recurrence.get_automatic_updates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[prev phrase embedding.W,\n",
       " gru0.W_in_to_updategate,\n",
       " gru0.W_hid_to_updategate,\n",
       " gru0.b_updategate,\n",
       " gru0.W_in_to_resetgate,\n",
       " gru0.W_hid_to_resetgate,\n",
       " gru0.b_resetgate,\n",
       " gru0.W_in_to_hidden_update,\n",
       " gru0.W_hid_to_hidden_update,\n",
       " gru0.b_hidden_update,\n",
       " gru0.hid_init,\n",
       " W,\n",
       " YetAnotherGRULayer.b_to_resetgate,\n",
       " YetAnotherGRULayer.W_clipping_layer.grad_clip_to_resetgate,\n",
       " YetAnotherGRULayer.b_to_updategate,\n",
       " YetAnotherGRULayer.W_clipping_layer.grad_clip_to_updategate,\n",
       " YetAnotherGRULayer.b_to_hidden_update,\n",
       " YetAnotherGRULayer.W_clipping_layer.grad_clip_to_hidden_update,\n",
       " YetAnotherGRULayer.W_prev gru state_to_resetgate,\n",
       " YetAnotherGRULayer.W_prev gru state_to_updategate,\n",
       " YetAnotherGRULayer.W_prev gru state_to_hidden_update,\n",
       " W,\n",
       " b,\n",
       " W,\n",
       " b]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_params(generative_recurrence.recurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
