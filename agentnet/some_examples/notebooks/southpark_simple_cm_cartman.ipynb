{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=gpu2\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=device=gpu2\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7285/7285 [00:03<00:00, 1936.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23281 out of 23281 tokens, coverage=1.00000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.southpark import get_conversations\n",
    "conversations = get_conversations(\"/srv/hd7/jheuristic/cartman/sp.json\")\n",
    "    \n",
    "from utils.preprocessor import Preprocessor\n",
    "\n",
    "preproc = Preprocessor.from_conversations(conversations,verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/thenv/local/lib/python2.7/site-packages/agentnet/agent/recurrence.py:228: UserWarning: You are giving Recurrence an input sequence of undefined length (None).\n",
      "Make sure it is always above <unspecified>(n_steps) you specified for recurrence\n",
      "  \"Make sure it is always above {}(n_steps) you specified for recurrence\".format(n_steps or \"<unspecified>\"))\n",
      "/home/jheuristic/thenv/local/lib/python2.7/site-packages/agentnet/agent/recurrence.py:453: UserWarning: Warning: recurrent loop without unroll_scan got nonempty random state updates list. That happened because there is some source of randomness (e.g. dropout) inside recurrent step graph. To compile such graph, one must either call .get_automatic_updates() right after .get_output and pass these updates to a function, or use no_defalt_updates=True when compiling theano.function.\n",
      "  warn(\"Warning: recurrent loop without unroll_scan got nonempty random state updates list. That happened\"\n"
     ]
    }
   ],
   "source": [
    "from models.twoline_model import ConversationModel\n",
    "model = ConversationModel(preproc,bottleneck_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len=10\n",
    "batch_size=100\n",
    "n_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7285/7285 [00:04<00:00, 1639.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.generate import get_phrase_pairs,iterate_minibatches\n",
    "\n",
    "convs_ix = list(preproc.preprocess_conversations(conversations,verbose=True,max_len=max_len))\n",
    "\n",
    "prev_phrases,reference_answers = get_phrase_pairs(convs_ix,\n",
    "                                                  speaker_filter = lambda s1,s2: 'cartman' in s2).swapaxes(0,1).astype('int32')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch_counter = 1\n",
    "ce = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "for _ in range(n_epochs):\n",
    "    for b_x,b_y in iterate_minibatches([prev_phrases,reference_answers],batch_size,shuffle=True):\n",
    "        ce.append(model.train_fun(b_x,b_y))\n",
    "        \n",
    "        epoch_counter +=1\n",
    "        \n",
    "        if epoch_counter %25==0:\n",
    "            print epoch_counter,'iterations...'\n",
    "    print \"beginning new loop...\"\n",
    "    plt.plot(ce)\n",
    "    plt.show()\n",
    "    \n",
    "    ph =preproc.ix_to_phrase(b_x[0])\n",
    "    print 'A:', ph\n",
    "    print 'B:', model.reply(ph)\n",
    "    print 'B true:',preproc.ix_to_phrase(b_y[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.utils.persistence import save\n",
    "save(model.decoder_training_rec,\"/srv/hd7/jheuristic/agentnet_snapshots/southpark_simple_cm_cartman_epoch%i.pcl\"%epoch_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<agentnet.agent.recurrence.Recurrence at 0x3c11110>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agentnet.utils.persistence import load\n",
    "load(model.decoder_training_rec,\"/srv/hd7/jheuristic/agentnet_snapshots/southpark_simple_cm_cartman_epoch15484.pcl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Who's Cartman?\n",
      "beth ! my god ! go !\n",
      ">> Who are you?\n",
      "i am the dawg , the big bad dawg\n",
      ">> what's up?\n",
      "this is a jew , kenny ! my\n",
      ">> Are you serious?\n",
      "it look . get it from here\n",
      ">> What for?\n",
      "i don't know . there's my dad !\n",
      ">> Do you know him?\n",
      "it looks like kyle . i need a\n",
      ">> No!\n",
      "a mountain lion ! okay\n",
      ">> Fuck you!\n",
      "yaaaaah ! it's hard , kyle ! !\n",
      ">> What do you think?\n",
      "shooting a d - good . . .\n",
      ">> What a mess!\n",
      "i am a gay of my child .\n",
      ">> Are you gay?\n",
      "it works . get my back to\n",
      ">> They killed kenny!\n",
      "they come ! my\n",
      ">> Jesus!\n",
      "uh - huh . .\n"
     ]
    }
   ],
   "source": [
    "model.greed.set_value(1.5)\n",
    "\n",
    "Q = [\"Who's Cartman?\",\n",
    "     \"Who are you?\",\n",
    "     \"what's up?\",\n",
    "     \"Are you serious?\",\n",
    "     \"What for?\",\n",
    "     \"Do you know him?\",\n",
    "     \"No!\",\n",
    "     \"Fuck you!\",\n",
    "     \"What do you think?\",\n",
    "     \"What a mess!\",\n",
    "     \"Are you gay?\",\n",
    "     \"They killed kenny!\",\n",
    "     \"Jesus!\"\n",
    "    ]\n",
    "for q in Q:\n",
    "    print '>>',q\n",
    "    print model.reply(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
