{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=gpu0\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=device=gpu0\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.southpark import get_conversations\n",
    "#southpark stuff\n",
    "conversations_southpark = get_conversations(\"/srv/hd7/jheuristic/cartman/sp.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7285/7285 [00:03<00:00, 2160.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23281 out of 23281 tokens, coverage=1.00000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocessor import Preprocessor\n",
    "sp_tokens = Preprocessor.from_conversations(conversations_southpark,verbose=True).tokens[3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18713837it [00:15, 1205766.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "with open(\"/srv/hd7/jheuristic/cartman/OpenSubtitles2016.en-ru.en\") as f:\n",
    "    opensub_lines = [['opensub',line] for line in tqdm(f)]\n",
    "    \n",
    "batch_size = 100\n",
    "opensub_conv_chunks = [opensub_lines[i:i+batch_size] \n",
    "                       for i in range(0,len(opensub_lines) - batch_size +1,batch_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os_tokens = Preprocessor.from_conversations(opensub_conv_chunks,max_tokens=50000,verbose=True).tokens[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc = Preprocessor(list(set(os_tokens+sp_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/srv/hd7/jheuristic/Downloads/opensub_en_tokens.pcl\",'w') as fout:\n",
    "    pickle.dump(preproc.tokens,fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../utils/preprocessor.py:22: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  token_to_ix = {t:i for i,t in enumerate(tokens)}\n",
      "../utils/preprocessor.py:23: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  token_to_ix = defaultdict(lambda:token_to_ix[\"UNK\"],token_to_ix)\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocessor import Preprocessor\n",
    "import pickle\n",
    "with open(\"/srv/hd7/jheuristic/Downloads/opensub_en_tokens.pcl\") as fin:\n",
    "    preproc = Preprocessor(pickle.load(fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40m (CNMeM is disabled, cuDNN Version is too old. Update to v5, was 4004.)\n",
      "/home/jheuristic/thenv/local/lib/python2.7/site-packages/agentnet/agent/recurrence.py:228: UserWarning: You are giving Recurrence an input sequence of undefined length (None).\n",
      "Make sure it is always above <unspecified>(n_steps) you specified for recurrence\n",
      "  \"Make sure it is always above {}(n_steps) you specified for recurrence\".format(n_steps or \"<unspecified>\"))\n",
      "/home/jheuristic/thenv/local/lib/python2.7/site-packages/agentnet/agent/recurrence.py:453: UserWarning: Warning: recurrent loop without unroll_scan got nonempty random state updates list. That happened because there is some source of randomness (e.g. dropout) inside recurrent step graph. To compile such graph, one must either call .get_automatic_updates() right after .get_output and pass these updates to a function, or use no_defalt_updates=True when compiling theano.function.\n",
      "  warn(\"Warning: recurrent loop without unroll_scan got nonempty random state updates list. That happened\"\n"
     ]
    }
   ],
   "source": [
    "from models.twoline_model import ConversationModel\n",
    "model = ConversationModel(preproc,bottleneck_size=2048,emb_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conversations = conversations_southpark + opensub_conv_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len=30\n",
    "batch_size=25\n",
    "n_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/194423 [00:00<?, ?it/s]../utils/preprocessor.py:75: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  tokens = [self.token_to_ix[t] for t in self.tokenizer.tokenize(self.preprocess_phrase(phrase))]\n",
      "  5%|▍         | 8940/194423 [00:09<09:30, 325.19it/s]"
     ]
    }
   ],
   "source": [
    "from utils.generate import get_phrase_pairs,iterate_minibatches\n",
    "\n",
    "convs_ix = list(preproc.preprocess_conversations(conversations,verbose=True,max_len=max_len))\n",
    "\n",
    "prev_phrases,reference_answers = get_phrase_pairs(convs_ix,\n",
    "                                                  speaker_filter = lambda s1,s2: True).swapaxes(0,1).astype('int32')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch_counter = 1\n",
    "ce = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "for _ in range(n_epochs):\n",
    "    for b_x,b_y in iterate_minibatches([prev_phrases,reference_answers],batch_size,shuffle=True):\n",
    "        ce.append(model.train_fun(b_x,b_y))\n",
    "        \n",
    "        epoch_counter +=1\n",
    "        \n",
    "        if epoch_counter %25==0:\n",
    "            print epoch_counter,'iterations...'\n",
    "    print \"beginning new loop...\"\n",
    "    plt.plot(ce)\n",
    "    plt.show()\n",
    "    \n",
    "    ph =preproc.ix_to_phrase(b_x[0])\n",
    "    print 'A:', ph\n",
    "    print 'B:', model.reply(ph)\n",
    "    print 'B true:',preproc.ix_to_phrase(b_y[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.utils.persistence import save\n",
    "save(model.decoder_training_rec,\"/srv/hd7/jheuristic/agentnet_snapshots/opensub_simple_cm_1024n_cartman_epoch%i.pcl\"%epoch_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
