{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./tokens.txt\") as fin:\n",
    "    tokens = filter(len,fin.read().split('\\n'))\n",
    "    \n",
    "tokens.append(\"_BOS_\") #beginning of sentence. Omitted in danet\n",
    "tokens.append(\"_PAD_\") #padding. Omitted in danet\n",
    "\n",
    "UNK_ix,BOS_ix,EOS_ix,PAD_ix = map(tokens.index,[\"_UNK_\",\"_BOS_\",\"_EOS_\",\"_PAD_\"])\n",
    "n_tokens = len(tokens)\n",
    "\n",
    "from collections import defaultdict\n",
    "token_to_ix = defaultdict(lambda:UNK_ix,{t:i for i,t in enumerate(tokens)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "def preprocess(lines,speaker=None,add_eos=True):\n",
    "    if type(lines) in (str,unicode):\n",
    "        lines = [lines]\n",
    "    \n",
    "    context=[]\n",
    "    for line in lines:\n",
    "        line = line.lower()\n",
    "        line = regex.sub(ur'(\\p{P}|`|~)', ur' \\1 ', line)\n",
    "        line_ix = map(token_to_ix.__getitem__,filter(len,line.split()))\n",
    "        if add_eos:\n",
    "            line_ix.append(EOS_ix)\n",
    "        context += line_ix\n",
    "            \n",
    "    if speaker is not None:\n",
    "        context.append(speaker)\n",
    "        \n",
    "    return context\n",
    "\n",
    "def ix_to_matrix(phrases_ix,max_len = None,):\n",
    "    max_len = max_len or max(map(len,phrases_ix))\n",
    "    \n",
    "    matrix = np.zeros((len(phrases_ix),max_len),dtype='int32') + PAD_ix\n",
    "    \n",
    "    for i,phrase_ix in enumerate(phrases_ix):\n",
    "        matrix[i,:min(len(phrase_ix),max_len)] = phrase_ix[:max_len]\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "def phrase_to_matrix(contexts,max_len = None,**kwargs):\n",
    "            \n",
    "    return ix_to_matrix([preprocess(phrases,**kwargs) for phrases in contexts],max_len=max_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from warnings import warn\n",
    "import numpy as np\n",
    "import theano\n",
    "theano.config.floatX='float32'\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "grad_clipping=5\n",
    "lstm_units = 1024\n",
    "emb_size=512\n",
    "bottleneck_units=256\n",
    "\n",
    "temperature = theano.shared(np.float32(1.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from pretrained_network.wrong_lstm_layer import WrongLSTMLayer\n",
    "from lasagne.layers import *\n",
    "\n",
    "class encoder:\n",
    "        \n",
    "    input_phrase  = T.imatrix(\"encoder phrase tokens\")\n",
    "    \n",
    "    l_in = InputLayer((None,None),input_phrase,name='context input')\n",
    "    l_mask = InputLayer((None,None),T.neq(input_phrase,PAD_ix),'context mask')\n",
    "    \n",
    "    l_emb = EmbeddingLayer(l_in,n_tokens,emb_size,name=\"context embedding\")\n",
    "    \n",
    "    \n",
    "    ####LSTMLayer with incorrect outputgate####\n",
    "    \n",
    "    l_lstm = WrongLSTMLayer(\n",
    "                        l_emb,\n",
    "                        lstm_units,\n",
    "                        name='encoder_lstm',\n",
    "                        grad_clipping=grad_clipping,\n",
    "                        mask_input = l_mask,\n",
    "                        only_return_final=True,\n",
    "                        peepholes=False)\n",
    "    \n",
    "    output = l_lstm\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pretrained_network.wrong_lstm_cell import WrongLSTMCell\n",
    "from agentnet import Recurrence\n",
    "from agentnet.resolver import  ProbabilisticResolver\n",
    "\n",
    "class decoder:\n",
    "    prev_cell = InputLayer((None,lstm_units),name='cell')\n",
    "    prev_out = InputLayer((None,lstm_units),name='out')\n",
    "    \n",
    "    #input\n",
    "    inp_word = InputLayer((None,))\n",
    "    word_embedding = EmbeddingLayer(inp_word,n_tokens,emb_size,\n",
    "                                         W=encoder.l_emb.W,name='emb')\n",
    "    encoder_lstm = InputLayer((None,lstm_units),name='encoder')\n",
    "    \n",
    "    #recurrent units\n",
    "    new_cell,new_out = WrongLSTMCell(prev_cell,prev_out,\n",
    "                                     input_or_inputs=[word_embedding,encoder_lstm],\n",
    "                                     name='decoder_lstm',peepholes=False\n",
    "                                    )\n",
    "    \n",
    "\n",
    "    bottleneck = DenseLayer(new_out,bottleneck_units,\n",
    "                              nonlinearity=T.tanh,\n",
    "                              name='decoder intermediate')\n",
    "\n",
    "    \n",
    "    next_word_probs = DenseLayer(bottleneck,n_tokens,\n",
    "                                 nonlinearity = lambda probs: T.nnet.softmax(probs/temperature),\n",
    "                                 name='decoder next word probas')\n",
    "\n",
    "    next_words = ProbabilisticResolver(next_word_probs,assume_normalized=True)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anet/AgentNet/agentnet/agent/recurrence.py:188: UserWarning: State_variables recommended type is OrderedDict.\n",
      "                Otherwise, order of agent state outputs from get_sessions and get_agent_reaction methods\n",
      "                may depend on python configuration.\n",
      "\n",
      "                Current order is: [<lasagne.layers.merge.ElemwiseMergeLayer object at 0x7f233910aa10>, <lasagne.layers.special.NonlinearityLayer object at 0x7f233910ab50>, <agentnet.resolver.probabilistic.ProbabilisticResolver object at 0x7f23391194d0>]\n",
      "                You may find OrderedDict in standard collections module: from collections import OrderedDict\n",
      "                \n",
      "  \"\"\".format(state_variables=list(self.state_variables.keys())))\n",
      "/root/anet/AgentNet/agentnet/agent/recurrence.py:573: UserWarning: Warning: recurrent loop without unroll_scan got nonempty random state updates list. That happened because there is some source of randomness (e.g. dropout) inside recurrent step graph. To compile such graph, one must either call .get_automatic_updates() right after .get_output and pass these updates to a function, or use no_defalt_updates=True when compiling theano.function.\n",
      "  warn(\"Warning: recurrent loop without unroll_scan got nonempty random state updates list. That happened\"\n"
     ]
    }
   ],
   "source": [
    "class generator:\n",
    "    \n",
    "    n_steps = T.iscalar()\n",
    "    bos_input_layer = InputLayer((None,),T.zeros((encoder.input_phrase.shape[0],),'int32')+BOS_ix, name=\"first input\")\n",
    "\n",
    "    recurrence = Recurrence(\n",
    "                           input_nonsequences={decoder.encoder_lstm:encoder.output},\n",
    "                           state_variables={decoder.new_cell:decoder.prev_cell,\n",
    "                                            decoder.new_out:decoder.prev_out,\n",
    "                                            decoder.next_words:decoder.inp_word},\n",
    "                           tracked_outputs=[decoder.next_words],\n",
    "                           state_init={decoder.next_words:bos_input_layer},\n",
    "                           n_steps=n_steps,\n",
    "                           unroll_scan=False,)\n",
    "    \n",
    "    weights = get_all_params(recurrence,trainable=True)    \n",
    "    \n",
    "    out = get_output(recurrence[decoder.next_words])\n",
    "    \n",
    "    generate = theano.function([encoder.input_phrase,n_steps],out,\n",
    "                              updates = recurrence.get_automatic_updates())\n",
    "    @staticmethod\n",
    "    def reply(phrase,max_len=25,**kwargs):\n",
    "        phrase_ix = phrase_to_matrix([phrase],**kwargs)\n",
    "        answer_ix = generator.generate(phrase_ix,max_len)[0]\n",
    "        if EOS_ix in answer_ix:\n",
    "            answer_ix = answer_ix[:list(answer_ix).index(EOS_ix)]\n",
    "        return ' '.join(map(tokens.__getitem__, answer_ix))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class critic:\n",
    "    #using n_units = 2 cuz https://github.com/yandexdataschool/AgentNet/issues/83\n",
    "    state_values = DenseLayer(decoder.new_cell,\n",
    "                              num_units=2,\n",
    "                              nonlinearity=None,\n",
    "                              name=\"state values\")\n",
    "    \n",
    "    weights = [param for param in get_all_params(state_values,trainable=True) \n",
    "                     if param not in get_all_params(generator.recurrence,trainable=True)]    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<agentnet.agent.recurrence.Recurrence at 0x7f2336d00a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agentnet.utils.persistence import save,load\n",
    "load(generator.recurrence,\"pretrained_network/weights.pcl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh , god .\n",
      "i ' m six .\n",
      "i ' m 11 .\n",
      "i ' m 16 .\n",
      "i ' m 17 .\n"
     ]
    }
   ],
   "source": [
    "temperature.set_value(np.float32(0.5))\n",
    "for i in range(5):\n",
    "    print generator.reply([\"Hello!\",\"hello .\",\"How old are you, dude?\"],20)\n",
    "    \n",
    "temperature.set_value(np.float32(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anet/AgentNet/agentnet/agent/recurrence.py:188: UserWarning: State_variables recommended type is OrderedDict.\n",
      "                Otherwise, order of agent state outputs from get_sessions and get_agent_reaction methods\n",
      "                may depend on python configuration.\n",
      "\n",
      "                Current order is: [<lasagne.layers.merge.ElemwiseMergeLayer object at 0x7f233910aa10>, <lasagne.layers.special.NonlinearityLayer object at 0x7f233910ab50>]\n",
      "                You may find OrderedDict in standard collections module: from collections import OrderedDict\n",
      "                \n",
      "  \"\"\".format(state_variables=list(self.state_variables.keys())))\n",
      "/root/anet/AgentNet/agentnet/agent/recurrence.py:295: UserWarning: You are giving Recurrence an input sequence of undefined length (None).\n",
      "Make sure it is always above <unspecified>(n_steps) you specified for recurrence\n",
      "  \"Make sure it is always above {}(n_steps) you specified for recurrence\".format(n_steps or \"<unspecified>\"))\n"
     ]
    }
   ],
   "source": [
    "import lasagne \n",
    "class trainer:\n",
    "    \"\"\"contains a recurrent loop where network is fed with reference answers instead of her own outputs.\n",
    "    Also contains some functions that train network in that mode.\"\"\"\n",
    "    #training recurrence\n",
    "    reference_answers = T.imatrix(\"decoder reference answers\")\n",
    "    \n",
    "    bos_column = T.zeros((reference_answers.shape[0],1),'int32')+BOS_ix\n",
    "    reference_answers_bos = T.concatenate((bos_column,reference_answers ),axis=1)  #prepend BOS\n",
    "        \n",
    "    l_ref = InputLayer((None,None),reference_answers_bos,name='context input')\n",
    "    l_ref_mask = InputLayer((None,None),T.neq(reference_answers_bos,PAD_ix),'context mask')\n",
    "\n",
    "    recurrence = Recurrence(input_sequences={decoder.inp_word:l_ref},\n",
    "                           input_nonsequences={decoder.encoder_lstm:encoder.output},\n",
    "                           state_variables={decoder.new_cell:decoder.prev_cell,\n",
    "                                            decoder.new_out:decoder.prev_out,},\n",
    "                           tracked_outputs=[decoder.next_word_probs],#<ADDWHATEVERYOUWANT>,]\n",
    "                           mask_input=l_ref_mask,\n",
    "                           unroll_scan=False,)\n",
    "    \n",
    "    \n",
    "    P_seq = get_output(recurrence[decoder.next_word_probs])\n",
    "    #V_seq = whateveryouadded\n",
    "    \n",
    "    ############################\n",
    "    ###loglikelihood training###\n",
    "    ############################\n",
    "    predicted_probas = P_seq[:,:-1].reshape((-1,n_tokens))+1e-6\n",
    "    target_values = reference_answers.ravel()\n",
    "    llh = lasagne.objectives.categorical_crossentropy(predicted_probas,target_values)\n",
    "    llh_loss = llh.mean()\n",
    "\n",
    "    #only train over generator weights since state value estimator does not influence likelihood (disconnected)\n",
    "    llh_updates = lasagne.updates.adam(llh_loss,generator.weights,0.001)\n",
    "\n",
    "    train_llh_step = theano.function([encoder.input_phrase,reference_answers],llh_loss,updates=llh_updates)\n",
    "    get_llh = theano.function([encoder.input_phrase,reference_answers],llh)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12.79598808,  13.08443642,  13.78222275], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.get_llh([[1,2,3]],[[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
