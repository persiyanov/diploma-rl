{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=gpu5,floatX=float32,exception_verbosity=high,lib.cnmem=0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 5: GeForce GTX 1080 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "# import phrase2matrix, tokens, token2idx, UNK_ix, EOS_ix\n",
    "from mymodule.data_stuff import *\n",
    "from collections import deque\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "# %env THEANO_FLAGS=device=gpu5,floatX=float32,exception_verbosity=high,lib.cnmem=0.95,mode=FAST_RUN\n",
    "from warnings import warn\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from collections import OrderedDict\n",
    "import lasagne\n",
    "\n",
    "from lasagne.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_all_contexts(context_size=2, verbose=100000):\n",
    "    with open('./open_subtitles_en_raw') as fin:\n",
    "        lines = [l.strip() for l in fin]\n",
    "\n",
    "    contexts = []\n",
    "    curr_context = deque(lines[:context_size], context_size)\n",
    "    curr_answer = lines[context_size]\n",
    "    \n",
    "    t = 0\n",
    "    for line in lines[context_size+1:]:\n",
    "        contexts.append({'context':list(curr_context), 'answer': curr_answer})\n",
    "\n",
    "        if t % verbose == 0:\n",
    "            print(t)\n",
    "        curr_context.append(curr_answer)\n",
    "        curr_answer = line.strip()\n",
    "\n",
    "        t += 1\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('contexts.pkl', 'rb') as fin:\n",
    "    contexts = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor-Critic Dialogue Model \n",
    "\n",
    "**! (symbolic expressions start from here)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GRAD_CLIP = 5\n",
    "N_LSTM_UNITS = 1024\n",
    "EMB_SIZE = 512\n",
    "BOTTLENECK_UNITS = 256\n",
    "\n",
    "\n",
    "TEMPERATURE = theano.shared(np.float32(1.), name='temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "* Just convolves sequence of input words into final hidden vector (so outputs [batch_size, N_LSTM_UNITS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pretrained_network.wrong_lstm_layer import WrongLSTMLayer\n",
    "class Enc:\n",
    "    ### THEANO GRAPH INPUT ###\n",
    "    input_phrase = T.imatrix(\"encoder phrase tokens\")\n",
    "    ##########################\n",
    "    \n",
    "    l_in = InputLayer((None, None), input_phrase, name='context input')\n",
    "    l_mask = InputLayer((None, None), T.neq(input_phrase, PAD_ix), name='context mask')\n",
    "    \n",
    "    l_emb = EmbeddingLayer(l_in, N_TOKENS, EMB_SIZE, name=\"context embedding\")\n",
    "    \n",
    "    \n",
    "    ####LSTMLayer with incorrect outputgate####\n",
    "    \n",
    "    l_lstm = LSTMLayer(\n",
    "                        l_emb,\n",
    "                        N_LSTM_UNITS,\n",
    "                        name='encoder_lstm',\n",
    "                        grad_clipping=GRAD_CLIP,\n",
    "                        mask_input=l_mask,\n",
    "                        only_return_final=True,\n",
    "                        peepholes=False)\n",
    "    \n",
    "    weights = get_all_params(l_lstm, trainable=True)\n",
    "    \n",
    "    output = l_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This defines one step of decoder.\n",
    "\n",
    "* Decoder takes next things as input (at each tick!): ``(prev_cell, prev_hid, inp_word, encoder_output)``\n",
    "* Decoder makes computations and output: ``(next_cell, next_hid, next_word)`` which will be passed as inputs at the next tick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pretrained_network.wrong_lstm_cell import WrongLSTMCell\n",
    "from agentnet import Recurrence\n",
    "from agentnet.resolver import  ProbabilisticResolver\n",
    "from agentnet.memory import LSTMCell\n",
    "\n",
    "class Dec:\n",
    "    # Define inputs of decoder at each time step.\n",
    "    prev_cell = InputLayer((None, N_LSTM_UNITS), name='cell')\n",
    "    prev_hid = InputLayer((None, N_LSTM_UNITS), name='hid')\n",
    "    input_word = InputLayer((None,))\n",
    "    encoder_lstm = InputLayer((None, N_LSTM_UNITS), name='encoder')\n",
    "\n",
    "    \n",
    "    # Embed input word and use the same embeddings as in the encoder.\n",
    "    word_embedding = EmbeddingLayer(input_word, N_TOKENS, EMB_SIZE,\n",
    "                                    W=Enc.l_emb.W, name='emb')\n",
    "    \n",
    "    \n",
    "    # This is not WrongLSTMLayer! *Cell is used for one-tick networks.\n",
    "    new_cell, new_hid = LSTMCell(prev_cell, prev_hid,\n",
    "                                      input_or_inputs=[word_embedding, encoder_lstm],\n",
    "                                      name='decoder_lstm',\n",
    "                                      peepholes=False)\n",
    "    \n",
    "    # Define parts for new word prediction. Bottleneck is a hack for reducing time complexity.\n",
    "    bottleneck = DenseLayer(new_hid, BOTTLENECK_UNITS, nonlinearity=T.tanh, name='decoder intermediate')\n",
    "\n",
    "    \n",
    "    next_word_probs = DenseLayer(bottleneck, N_TOKENS,\n",
    "                                 nonlinearity=lambda probs: T.nnet.softmax(probs/TEMPERATURE),\n",
    "                                 name='decoder next word probas')\n",
    "\n",
    "    next_words = ProbabilisticResolver(next_word_probs, assume_normalized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator unrolls decoder for ``n_steps``\n",
    "\n",
    "* It uses ``Recurrence`` class from ``agentnet``.\n",
    "\n",
    "* ``theano.scan`` fn takes arguments in order: ``seq1, seq2,..,output1,output2,..,nonseq1,nonseq2,...``\n",
    "* ``Recurrence`` unrolls ``Dec`` for `n_steps`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.5/site-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=1] You called get_output from recurrence several times without gathering the updates.\n",
      "(A) If you wanted to get two outputs from recurrence, use NOT\n",
      ">>>out1 = get_output(rec[layer1])\n",
      ">>>out2 = get_output(rec[layer2])\n",
      "but instead:\n",
      ">>>out1,out2 = get_output((rec[layer1],rec[layer2])) #or rec[layer1,layer2].\n",
      "(B) If you want to run recurrence several times and accumulate updates from all runs,use get_output(...,accumulate_updates=True) to silence the warning.\n",
      "(C) If you want to get rid of old updates, use get_output(...,accumulate_updates=False)\n",
      "\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n",
      "/anaconda3/lib/python3.5/site-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=2] Recurrent loop without unroll_scan got nonempty random state updates list. That happened because there is some source of randomness (e.g. dropout) inside recurrent step graph. To compile such graph, one must either call .get_automatic_updates() right after .get_output and pass these updates to a function when compiling theano.function.\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n",
      "/anaconda3/lib/python3.5/site-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=2] You are giving Recurrence an input sequence of undefined length (None).\n",
      "Make sure it is always above <unspecified>(n_steps) you specified for recurrence\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n",
      "/anaconda3/lib/python3.5/site-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=1] You called get_output from recurrence several times without gathering the updates.\n",
      "(A) If you wanted to get two outputs from recurrence, use NOT\n",
      ">>>out1 = get_output(rec[layer1])\n",
      ">>>out2 = get_output(rec[layer2])\n",
      "but instead:\n",
      ">>>out1,out2 = get_output((rec[layer1],rec[layer2])) #or rec[layer1,layer2].\n",
      "(B) If you want to run recurrence several times and accumulate updates from all runs,use get_output(...,accumulate_updates=True) to silence the warning.\n",
      "(C) If you want to get rid of old updates, use get_output(...,accumulate_updates=False)\n",
      "\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n",
      "/anaconda3/lib/python3.5/site-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=2] Recurrent loop without unroll_scan got nonempty random state updates list. That happened because there is some source of randomness (e.g. dropout) inside recurrent step graph. To compile such graph, one must either call .get_automatic_updates() right after .get_output and pass these updates to a function when compiling theano.function.\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n"
     ]
    }
   ],
   "source": [
    "class Gen:\n",
    "    n_steps = theano.shared(25)\n",
    "    # This theano tensor is used as first input word for decoder.\n",
    "    bos_input_var = T.zeros((Enc.input_phrase.shape[0],), 'int32')+BOS_ix\n",
    "    \n",
    "    bos_input_layer = InputLayer((None,), bos_input_var, name=\"first input\")\n",
    "\n",
    "    recurrence = Recurrence(\n",
    "        # This means that encoder.output passed to decoder.encoder_lstm input at each tick.\n",
    "        input_nonsequences={Dec.encoder_lstm: Enc.output},\n",
    "        \n",
    "        # This defines how outputs moves to inputs at each tick in decoder. \n",
    "        # These corresponds to outputs in theano scan function.\n",
    "        state_variables=OrderedDict([(Dec.new_cell, Dec.prev_cell),\n",
    "                                     (Dec.new_hid, Dec.prev_hid),\n",
    "                                     (Dec.next_words, Dec.input_word)]),\n",
    "        # We will need these probabilities for Actor-Critic algorithm.\n",
    "        tracked_outputs=[Dec.next_word_probs],\n",
    "        state_init={Dec.next_words: bos_input_layer},\n",
    "        n_steps=n_steps,\n",
    "        unroll_scan=False)\n",
    "    \n",
    "    recurrence_outputs = get_output(recurrence)\n",
    "        \n",
    "    ##### DECODER UNROLLED #####\n",
    "    # Theano tensor which represents sequence of generated words and their probabilities.\n",
    "    words_seq = recurrence_outputs[Dec.next_words]\n",
    "    words_probs_seq = recurrence_outputs[Dec.next_word_probs]\n",
    "    \n",
    "    # Theano tensor which represents decoder hidden states.\n",
    "    dec_cell_seq = recurrence_outputs[Dec.new_cell]\n",
    "    dec_hid_seq = recurrence_outputs[Dec.new_hid]\n",
    "    ############################\n",
    "                                                 \n",
    "    generate = theano.function([Enc.input_phrase], [words_seq, dec_cell_seq, dec_hid_seq],\n",
    "                               updates=recurrence.get_automatic_updates())\n",
    "    \n",
    "    weights = get_all_params(recurrence, trainable=True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def reply(phrase, max_len=25, **kwargs):\n",
    "        old_value = Gen.n_steps.get_value()\n",
    "        \n",
    "        Gen.n_steps.set_value(max_len)\n",
    "        phrase_ix = phrase2matrix([phrase],**kwargs)\n",
    "        answer_ix = Gen.generate(phrase_ix)[0][0]\n",
    "        if EOS_ix in answer_ix:\n",
    "            answer_ix = answer_ix[:list(answer_ix).index(EOS_ix)]\n",
    "            \n",
    "        Gen.n_steps.set_value(old_value)\n",
    "        return ' '.join(map(tokens.__getitem__, answer_ix))\n",
    "        \n",
    "class GenTrain:\n",
    "    \"\"\"contains a recurrent loop where network is fed with reference answers instead of her own outputs.\n",
    "    Also contains some functions that train network in that mode.\"\"\"\n",
    "    \n",
    "    ### THEANO GRAPH INPUT. ###\n",
    "    reference_answers = T.imatrix(\"decoder reference answers\") # shape [batch_size, max_len]\n",
    "    ###########################\n",
    "    \n",
    "    bos_column = T.zeros((reference_answers.shape[0], 1), 'int32')+BOS_ix\n",
    "    reference_answers_bos = T.concatenate((bos_column, reference_answers), axis=1)  #prepend BOS\n",
    "    \n",
    "    l_ref_answers = InputLayer((None, None), reference_answers_bos, name='context input')\n",
    "    l_ref_mask = InputLayer((None, None), T.neq(reference_answers_bos, PAD_ix), name='context mask')\n",
    "    \n",
    "    recurrence = Recurrence(\n",
    "        input_nonsequences=OrderedDict([(Dec.encoder_lstm, Enc.output)]),\n",
    "        input_sequences=OrderedDict([(Dec.input_word, l_ref_answers)]),\n",
    "        state_variables=OrderedDict([(Dec.new_cell, Dec.prev_cell),\n",
    "                                     (Dec.new_hid, Dec.prev_hid)]),\n",
    "        tracked_outputs=[Dec.next_word_probs, Dec.next_words],\n",
    "        mask_input=l_ref_mask,\n",
    "        unroll_scan=False)\n",
    "    \n",
    "    recurrence_outputs = get_output(recurrence)\n",
    "    \n",
    "    P_seq = recurrence_outputs[Dec.next_word_probs]\n",
    "    \n",
    "    \n",
    "    ############################\n",
    "    ###loglikelihood training###\n",
    "    ############################\n",
    "    predicted_probas = P_seq[:, :-1].reshape((-1, N_TOKENS))+1e-6\n",
    "    target_labels = reference_answers.ravel()\n",
    "    \n",
    "    llh_loss = lasagne.objectives.categorical_crossentropy(predicted_probas, target_labels).mean()\n",
    "    \n",
    "    llh_updates = lasagne.updates.adam(llh_loss, Gen.weights, 0.001)\n",
    "    \n",
    "    train_step = theano.function([Enc.input_phrase, reference_answers], llh_loss,\n",
    "                                 updates=llh_updates+recurrence.get_automatic_updates())\n",
    "    get_llh = theano.function([Enc.input_phrase, reference_answers], llh_loss, no_default_updates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Actor-Critic part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load target list of words list__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples ['asswhole', 'moan', 'doggin', 'fistfucks', 'sadism', 'motherfucked', 'Paddy', 'porchmonkey', 'negress', 'boner']\n",
      "Number of target words 237\n"
     ]
    }
   ],
   "source": [
    "with open('./obscene_words.txt') as fin:\n",
    "    target_words = set()\n",
    "    for line in fin:\n",
    "        words_in_line = line.strip().split()\n",
    "        if len(words_in_line) == 1:\n",
    "            target_words.update(words_in_line)\n",
    "\n",
    "# target_words = list('.!,?')\n",
    "\n",
    "target_words.add('suck')\n",
    "target_words.add('goddamn')\n",
    "target_words.add('motherfucker')\n",
    "target_words.add('nigger')\n",
    "target_words.add('nigga')\n",
    "target_words.add('ass')\n",
    "target_words.add('crap')\n",
    "target_words.remove('fucking')\n",
    "target_words.remove('no')\n",
    "print(\"Some examples %s\" % list(target_words)[:10])\n",
    "\n",
    "target_idxs = set(filter(lambda x: x != UNK_ix, [token2idx[w] for w in target_words]))\n",
    "\n",
    "target_idxs_shared = theano.shared(np.array(list(target_idxs)))\n",
    "print(\"Number of target words %d\" % len(target_idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hack for symbolic computation of rewards**:\n",
    "1. Let suppose that we have list of tokens = [25,90,102]\n",
    "2. And we also have generated batch with shape [batch_size, n_steps] with word indices.\n",
    "3. For each word we want to check whether it is equals to any of tokens in our list.\n",
    "\n",
    "We can do this using theano (same as numpy) broadcasting:\n",
    "\n",
    "``T.eq(tokens[None,None,:], batch[:,:,None]).any(-1)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _calc_rewards(symbolic_batch):\n",
    "    assert symbolic_batch.ndim == 2\n",
    "    rewards = T.eq(target_idxs_shared[None, None, :], symbolic_batch[:, :, None]).any(-1)\n",
    "    rewards = T.cast(rewards, 'int32')\n",
    "    assert rewards.ndim == 2\n",
    "\n",
    "    # Find EOS_ix in batch\n",
    "    done_mask = T.eq(symbolic_batch, EOS_ix)\n",
    "    # Set done==True for all words after EOS_ix\n",
    "    done_mask = T.concatenate([T.zeros_like(done_mask[:,:1]), done_mask[:,:-1]], axis=1)\n",
    "    \n",
    "    is_alive = T.eq(T.cumsum(done_mask, axis=1), 0).astype('uint8')\n",
    "    return rewards, is_alive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critic\n",
    "\n",
    "* Critic uses decoder hidden+cell vectors as state.\n",
    "* Critic evaluates state values for `[hid_t, cell_t]` before predicting `word_t`.\n",
    "* As a reward for being in state `[hid_t, cell_t]` and generating word `word_t` we take 1 if word `word_t` is obscene, 0 otherwise.\n",
    "\n",
    "* During training, we can compute these rewards trivially (we just need to collect a dictionary of obscene words).\n",
    "* We use TD updates $V(s) \\leftarrow V(s) + \\alpha * (R + V(s') - V(s))$; for function approximation, its equivalent to ``new_weights = old_weights - alpha * grad(MSE(targetV, approxV), old_weights)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from agentnet.learning.generic import get_n_step_value_reference\n",
    "from theano.gradient import disconnected_grad\n",
    "\n",
    "class Critic:\n",
    "    rewards, is_alive = _calc_rewards(Gen.words_seq)  # both with shape [batch_size, n_steps]\n",
    "    rewards = -1 * rewards ## PREVENT FROM BAD WORDS\n",
    "    \n",
    "    critic_input_var = T.concatenate([Gen.dec_cell_seq, Gen.dec_hid_seq], axis=2)\n",
    "    \n",
    "    l_dec_cell_seq = InputLayer((None, None, 2*N_LSTM_UNITS), input_var=critic_input_var, name='l_decoder_sequence')\n",
    "    \n",
    "    l_critic_values = DenseLayer(l_dec_cell_seq, num_units=2048, num_leading_axes=2, name=\"critic_dense1\")\n",
    "    l_critic_values = DenseLayer(l_critic_values, num_units=1024, num_leading_axes=2, name=\"critic_dense2\")\n",
    "    l_critic_values = DenseLayer(l_critic_values, num_units=512, num_leading_axes=2, name=\"critic_dense3\")\n",
    "    l_critic_values = DenseLayer(l_critic_values, num_units=1, num_leading_axes=2, \n",
    "                                 nonlinearity=None, name='critic_values')\n",
    "    \n",
    "    critic_values_seq = get_output(l_critic_values)\n",
    "    # Now its shape [batch, n_steps, 1]. Reshape it to [batch, n_steps]\n",
    "    _old_shape = critic_values_seq.shape\n",
    "    critic_values_seq = critic_values_seq.reshape((_old_shape[0], _old_shape[1]))\n",
    "    \n",
    "    predict = theano.function([Enc.input_phrase], [Gen.words_seq, critic_values_seq, rewards, is_alive],\n",
    "                              allow_input_downcast=True, no_default_updates=True)\n",
    "    \n",
    "    predict_values_from_decoder = theano.function([Gen.dec_cell_seq, Gen.dec_hid_seq], critic_values_seq,\n",
    "                                           allow_input_downcast=True, no_default_updates=True)\n",
    "    \n",
    "    weights = get_all_params(l_critic_values, trainable=True)\n",
    "\n",
    "class CriticTrainer:\n",
    "    td_n_steps = 1\n",
    "    \n",
    "    V_predicted = Critic.critic_values_seq\n",
    "    \n",
    "    V_reference = get_n_step_value_reference(state_values=V_predicted,\n",
    "                                             rewards=Critic.rewards,\n",
    "                                             is_alive=Critic.is_alive,\n",
    "                                             n_steps=td_n_steps)\n",
    "    \n",
    "    # We must not propagate grads through target value (semi-gradient method).\n",
    "    V_reference = disconnected_grad(V_reference)\n",
    "    \n",
    "    td_loss = lasagne.objectives.squared_error(V_predicted, V_reference).sum(axis=1).mean()\n",
    "    td_updates = lasagne.updates.adam(td_loss, Critic.weights)\n",
    "    \n",
    "    train_step = theano.function([Enc.input_phrase], [td_loss, V_predicted, V_reference, Critic.rewards, Critic.is_alive],\n",
    "                                 updates=td_updates+Gen.recurrence.get_automatic_updates(),\n",
    "                                 allow_input_downcast=True)\n",
    "    \n",
    "    \n",
    "CT = CriticTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor\n",
    "\n",
    "Actor need to update policy (which is defined by `Gen`) using policy gradient: $\\nabla\\log\\pi(a|s)\\cdot A(s,a)$, where $A(s,a)$ is the advantage function of being in state $s$ and doing action $a$. In our case, $A(s,a) = R_1+\\gamma R_2+\\dots+\\gamma^nV(s')-V(s)$\n",
    "\n",
    "In code, the scheme looks like this:\n",
    "* Take __generated batch__ (actions, needed for computing rewards), corresponding __`dec_cell_seq, dec_hid_seq`__ (states, needed for computing advantage function) and __probabilities of words__ on each tick (policy, we will update it).\n",
    "* Calculate `rewards` and `is_alive` mask for this batch.\n",
    "* Calculate state-values using critic and target values (n_steps TD estimation of Q-function, e.g. `Critic.V_reference`). Compute advantage function and disconnect gradient through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ActorTrainer:\n",
    "    LLH_ALPHA = theano.shared(5.0)\n",
    "    \n",
    "    actions = Gen.words_seq  # shape [batch_size, n_steps]\n",
    "    _actions_ravel = actions.ravel()  # shape [batch_size*n_steps,]\n",
    "    \n",
    "    _word_probs = Gen.words_probs_seq\n",
    "    _old_shape = _word_probs.shape\n",
    "    _word_probs = _word_probs.reshape((-1, _old_shape[-1]))  # shape [batch_size*n_steps, vocab_size]\n",
    "    \n",
    "    _policy = _word_probs[T.arange(_word_probs.shape[0]), _actions_ravel]  # shape [batch_size*n_steps,]\n",
    "    \n",
    "    policy = _policy.reshape((_old_shape[0], _old_shape[1])) # shape [batch_size, n_steps]\n",
    "    advantage = CriticTrainer.V_reference-CriticTrainer.V_predicted\n",
    "    \n",
    "    pg_loss = (-T.log(policy) * disconnected_grad(advantage)).sum(axis=1).mean()\n",
    "    llh_loss = GenTrain.llh_loss\n",
    "    \n",
    "    loss = pg_loss + LLH_ALPHA * llh_loss\n",
    "    \n",
    "#     actor_weights = [param for param in Gen.weights if param not in Enc.weights]\n",
    "    actor_weights = actor_weights = [param for param in Gen.weights]\n",
    "    \n",
    "    grads = T.grad(loss, actor_weights)\n",
    "    grads = lasagne.updates.total_norm_constraint(grads, GRAD_CLIP)\n",
    "    \n",
    "    policy_updates = lasagne.updates.adam(grads, actor_weights)\n",
    "    \n",
    "    train_step = theano.function([Enc.input_phrase, GenTrain.reference_answers],\n",
    "                                 [pg_loss, llh_loss, policy, actions, advantage, Critic.rewards, Critic.is_alive],\n",
    "                                 updates=policy_updates+GenTrain.recurrence.get_automatic_updates()+Gen.recurrence.get_automatic_updates())\n",
    "    \n",
    "AT = ActorTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## How to train Critic\n",
    "\n",
    "__How do we train critic?__\n",
    "* Iterating over batches of data (it will be `Enc.input_phrase`)\n",
    "* Call `CT.train_step(batch)`.\n",
    "\n",
    "That's it! Simple.\n",
    "\n",
    "\n",
    "## How to train Actor-Critic\n",
    "\n",
    "**Training both actor-critic with policy gradient**:\n",
    "\n",
    "* Iterating over batches of data.\n",
    "* Call `loss, policy, actions, advantage, rewards, is_alive = AT.train_step(batch_context, batch_answers)`\n",
    "* Call `td_loss, _, _, _, _ = CT.train_step(batch_context)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Actor-Critic [look at bepolite-experiments.ipynb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
