{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=gpu5,floatX=float32,exception_verbosity=high,lib.cnmem=0.95,mode=FAST_RUN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 5: GeForce GTX 1080 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5105)\n",
      "/anaconda3/lib/python3.5/site-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=1] You called get_output from recurrence several times without gathering the updates.\n",
      "(A) If you wanted to get two outputs from recurrence, use NOT\n",
      ">>>out1 = get_output(rec[layer1])\n",
      ">>>out2 = get_output(rec[layer2])\n",
      "but instead:\n",
      ">>>out1,out2 = get_output((rec[layer1],rec[layer2])) #or rec[layer1,layer2].\n",
      "(B) If you want to run recurrence several times and accumulate updates from all runs,use get_output(...,accumulate_updates=True) to silence the warning.\n",
      "(C) If you want to get rid of old updates, use get_output(...,accumulate_updates=False)\n",
      "\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n",
      "/anaconda3/lib/python3.5/site-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=2] Recurrent loop without unroll_scan got nonempty random state updates list. That happened because there is some source of randomness (e.g. dropout) inside recurrent step graph. To compile such graph, one must either call .get_automatic_updates() right after .get_output and pass these updates to a function when compiling theano.function.\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n",
      "/anaconda3/lib/python3.5/site-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=2] You are giving Recurrence an input sequence of undefined length (None).\n",
      "Make sure it is always above <unspecified>(n_steps) you specified for recurrence\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n",
      "/anaconda3/lib/python3.5/site-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=1] You called get_output from recurrence several times without gathering the updates.\n",
      "(A) If you wanted to get two outputs from recurrence, use NOT\n",
      ">>>out1 = get_output(rec[layer1])\n",
      ">>>out2 = get_output(rec[layer2])\n",
      "but instead:\n",
      ">>>out1,out2 = get_output((rec[layer1],rec[layer2])) #or rec[layer1,layer2].\n",
      "(B) If you want to run recurrence several times and accumulate updates from all runs,use get_output(...,accumulate_updates=True) to silence the warning.\n",
      "(C) If you want to get rid of old updates, use get_output(...,accumulate_updates=False)\n",
      "\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n",
      "/anaconda3/lib/python3.5/site-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=2] Recurrent loop without unroll_scan got nonempty random state updates list. That happened because there is some source of randomness (e.g. dropout) inside recurrent step graph. To compile such graph, one must either call .get_automatic_updates() right after .get_output and pass these updates to a function when compiling theano.function.\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples ['cocksuka', 'doggiestyle', 'dildo', 'fooker', 'unwieldy', 'biatch', 'flange', 'doosh', 'damn', 'n1gger']\n",
      "Number of target words 236\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=device=gpu5,floatX=float32,exception_verbosity=high,lib.cnmem=0.95,mode=FAST_RUN\n",
    "%run ./dimanet-critic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "test_phrases = [['Hello! How are you?'],\n",
    "                ['How old are you?'],\n",
    "                ['Are you fucking kidding me?'],\n",
    "                ['Suck. What are you doing?'], \n",
    "                ['You are piece of shit!!!'], \n",
    "                ['holy fucking crap. you are motherfucker']]\n",
    "\n",
    "test_phrases_ids = phrase2matrix(test_phrases)\n",
    "\n",
    "from agentnet.utils.persistence import save,load\n",
    "load(Gen.recurrence, './weights/LM2.pkl')\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "TRAINING_TIME_IN_BATCHES = 500\n",
    "VERBOSITY = 10 # number of batches before printing\n",
    "NUM_BATCHES = len(contexts)//BATCH_SIZE\n",
    "LLH_ALPHA = [90.0, 70.0, 50.0, 30.0, 20.0]\n",
    "CHANGE_ALPHA_EVERY = 100\n",
    "SAVE_EVERY = 100\n",
    "MODELS_SUFFIX = '_bepolite_my_lm'\n",
    "\n",
    "AT.LLH_ALPHA.set_value(LLH_ALPHA[0])\n",
    "\n",
    "loss_history = {'critic':[], 'pg_loss':[], 'llh_loss':[]}\n",
    "rewards_history = []\n",
    "for nb, (batch_context, batch_answers) in enumerate(iterate_minibatches(contexts, BATCH_SIZE)):\n",
    "    if (nb + 1) >= TRAINING_TIME_IN_BATCHES:\n",
    "        print(\"TRAINING FINISHED!\")\n",
    "        break\n",
    "    \n",
    "    llh_alpha = LLH_ALPHA[min(int(nb/CHANGE_ALPHA_EVERY), len(LLH_ALPHA)-1)]\n",
    "    AT.LLH_ALPHA.set_value(llh_alpha)\n",
    "    \n",
    "    ## Training stuff.\n",
    "    pg_loss, llh_loss, policy, actions, advantage, rewards, is_alive = AT.train_step(batch_context, batch_answers)\n",
    "    critic_loss, _, _, _, _ = CT.train_step(batch_context)\n",
    "\n",
    "    loss_history['critic'].append(critic_loss)\n",
    "    loss_history['pg_loss'].append(pg_loss)\n",
    "    loss_history['llh_loss'].append(llh_loss)\n",
    "    rewards_history.append(rewards.sum(axis=1).mean())\n",
    "\n",
    "    #### PRINTING STUFF. ####\n",
    "    if (nb + 1) % VERBOSITY == 0:\n",
    "        clear_output(wait=True) \n",
    "\n",
    "        # Visualize answer with maximum reward.\n",
    "        idx = np.argmax((rewards*is_alive).sum(axis=1))\n",
    "        ans_seq, ans_rewards, ans_advantage = actions[idx], rewards[idx], advantage[idx]\n",
    "        answer_len = list(ans_seq).index(EOS_ix) if EOS_ix in ans_seq else len(ans_seq)\n",
    "\n",
    "        ans = [tokens[i] for i in ans_seq][:answer_len+1]\n",
    "        inp_phrase = [tokens[i] for i in batch_context[idx][:list(batch_context[idx]).index(EOS_ix)]]\n",
    "        corr_ans = [tokens[i] for i in batch_answers[idx][:list(batch_answers[idx]).index(EOS_ix)]]\n",
    "        print(\"Most rewarded answer: \", ans)\n",
    "        print(\"Input phrase: \", inp_phrase)\n",
    "        print(\"Correct answer: \", corr_ans)\n",
    "        plt.scatter(range(len(ans_rewards[:answer_len+1])), ans_rewards[:answer_len+1])\n",
    "#             plt.plot(ans_V_pred[:answer_len+1], label='predicted')\n",
    "#             plt.plot(ans_V_ref[:answer_len+1], label='reference')\n",
    "        plt.plot(ans_advantage[:answer_len+1], label='A(s,a)')\n",
    "        plt.ylim(ymin=0)\n",
    "        plt.yticks(np.arange(10))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Answering on test phrases.\n",
    "        print(\"Answers on test phrases:\")\n",
    "        words_seq, critic_values, _, _ = Critic.predict(test_phrases_ids)\n",
    "        answers = []\n",
    "        for i in range(words_seq.shape[0]):\n",
    "            answer = words_seq[i]\n",
    "            if EOS_ix in answer:\n",
    "                answer = answer[:list(answer).index(EOS_ix)]\n",
    "            answers.append([tokens[idx] for idx in answer])\n",
    "\n",
    "        print(\"Processed {}/{} batches in current epoch\".format(nb+1, NUM_BATCHES))\n",
    "        print(\"LLH_ALPHA = {0:.3f}\".format(float(AT.LLH_ALPHA.get_value())))\n",
    "        print(\"Critic Loss (averaged with last 10 batches): {0:.5f}\".format(np.mean(loss_history['critic'][-10:])))\n",
    "#             print(\"Actor Loss (averaged with last 10 batches): {0:.5f}\".format(np.mean(loss_history['actor'][-10:])))\n",
    "        print(\"Avg reward: {0:.5f}\".format(np.mean(rewards_history[-10:])))\n",
    "        print(\"Loss history:\")\n",
    "        plt.plot(loss_history['critic'], label='critic')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.plot(loss_history['pg_loss'], label='pg_loss')\n",
    "        plt.plot(loss_history['llh_loss'], label='llh_loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        for i in range(len(test_phrases)):\n",
    "            print(\"Phrase:\\t\", test_phrases[i])\n",
    "            answer_tok_critic_value = zip(answers[i], critic_values[i])\n",
    "            print(\"Answer:\\t\",)\n",
    "            for tok,value in answer_tok_critic_value:\n",
    "                print('\"{}\"({:.3f}) '.format(tok, value),)\n",
    "        print('---'*5)\n",
    "        print(\"Answers on 'hello world!':\")\n",
    "        for i in range(5):\n",
    "            print(Gen.reply('hello world!'))\n",
    "\n",
    "    if nb % SAVE_EVERY == 0:\n",
    "        criticfname = './weights/critic{}{}.pkl'.format(MODELS_SUFFIX, LLH_ALPHA)\n",
    "        actorfname = './weights/actor{}{}.pkl'.format(MODELS_SUFFIX, LLH_ALPHA)\n",
    "        print(\"Save actor and critic weights to '{}' and '{}'\".format(criticfname, actorfname))\n",
    "        save(Critic.l_critic_values, criticfname)\n",
    "        save(Gen.recurrence, actorfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward & LLH checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.utils.persistence import load\n",
    "get_rewards = theano.function([Enc.input_phrase], [Critic.rewards, Gen.words_seq], allow_input_downcast=True, no_default_updates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<agentnet.agent.recurrence.Recurrence at 0x7f2fab52c518>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load(Gen.recurrence, './weights/LM2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEMPERATURE.set_value(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are ?\n",
      "you ' re lucky .\n",
      "eight .\n",
      "nineteen .\n",
      "i ' m 10 .\n",
      "that ' s what you call mentions me too .\n",
      "i don ' t know .\n",
      "is this your son ?\n",
      "have you ?\n",
      "five hundred ?\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(Gen.reply('how old are you?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is our dance fooled tonight !\n",
      "what ?\n",
      "_UNK_ , my dear _UNK_ , i ' m a racist . \"\n",
      "it doesn ' t matter .\n",
      "sorry i dragged you along .\n",
      "did he go to jail ?\n",
      "hello .\n",
      "who did it ?\n",
      "get a nice my from the front .\n",
      "does that look okay ?\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(Gen.reply('get the fuck out!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rewards_and_llh(batch_size=64, num_batches=10000):\n",
    "    rewards = []\n",
    "    llhs = []\n",
    "\n",
    "    for nb, (batch_context, batch_answers) in tqdm.tqdm_notebook(enumerate(iterate_minibatches(contexts, batch_size))):\n",
    "        if nb <= TRAINING_TIME_IN_BATCHES:\n",
    "            continue\n",
    "        if nb-TRAINING_TIME_IN_BATCHES >= num_batches:\n",
    "#         if nb >= num_batches:\n",
    "            break\n",
    "        b_rewards, b_answers = get_rewards(batch_context)\n",
    "        rewards.extend(list(b_rewards.sum(axis=1)))\n",
    "        llhs.append(GenTrain.get_llh(batch_context, batch_answers))\n",
    "    return rewards, llhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rewards, llhs = get_rewards_and_llh(64, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.2018166, -0.050306403201600798)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.mean(llhs)), np.mean(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now calculate reward over batches where input contains obscene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 400\n",
    "NUM_BATCHES = 1000\n",
    "rewards = []\n",
    "\n",
    "\n",
    "for nb, (batch_context, batch_answers) in tqdm.tqdm_notebook(enumerate(iterate_minibatches(contexts, BATCH_SIZE))):\n",
    "    if nb >= NUM_BATCHES:\n",
    "        break\n",
    "    mask = (batch_context[:, :, None] == np.array(list(target_idxs))[None, None, :]).any(-1).any(-1)\n",
    "    bb = batch_context[mask]\n",
    "        \n",
    "    b_rewards, b_answers = get_rewards(bb)\n",
    "    rewards.extend(list(b_rewards.sum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5h1t',\n",
       " '5hit',\n",
       " 'Eskimo',\n",
       " 'Indian',\n",
       " 'Jerry',\n",
       " 'Kraut',\n",
       " 'LEN',\n",
       " 'Paddy',\n",
       " 'Paki',\n",
       " 'Pygmy',\n",
       " 'Taffy',\n",
       " 'WASP',\n",
       " 'Yank',\n",
       " 'Yankee',\n",
       " 'a2m',\n",
       " 'a55',\n",
       " 'a_s_s',\n",
       " 'adult',\n",
       " 'amateur',\n",
       " 'anal',\n",
       " 'anilingus',\n",
       " 'anus',\n",
       " 'ar5e',\n",
       " 'arrse',\n",
       " 'arse',\n",
       " 'arsehole',\n",
       " 'ass',\n",
       " 'ass-fucker',\n",
       " 'ass-hat',\n",
       " 'ass-hole',\n",
       " 'ass-jabber',\n",
       " 'ass-pirate',\n",
       " 'assbag',\n",
       " 'assbandit',\n",
       " 'assbanger',\n",
       " 'assbite',\n",
       " 'assclown',\n",
       " 'asscock',\n",
       " 'asscracker',\n",
       " 'asses',\n",
       " 'assface',\n",
       " 'assfuck',\n",
       " 'assfucker',\n",
       " 'assfukka',\n",
       " 'assgoblin',\n",
       " 'asshat',\n",
       " 'asshead',\n",
       " 'asshole',\n",
       " 'assholes',\n",
       " 'asshopper',\n",
       " 'assjacker',\n",
       " 'asslick',\n",
       " 'asslicker',\n",
       " 'assmonkey',\n",
       " 'assmucus',\n",
       " 'assmunch',\n",
       " 'assmuncher',\n",
       " 'assnigger',\n",
       " 'asspirate',\n",
       " 'assshit',\n",
       " 'assshole',\n",
       " 'asssucker',\n",
       " 'asswad',\n",
       " 'asswhole',\n",
       " 'asswipe',\n",
       " 'autoerotic',\n",
       " 'axwound',\n",
       " 'b!tch',\n",
       " 'b00bs',\n",
       " 'b17ch',\n",
       " 'b1tch',\n",
       " 'ballbag',\n",
       " 'ballsack',\n",
       " 'bampot',\n",
       " 'bangbros',\n",
       " 'bareback',\n",
       " 'bastard',\n",
       " 'beaner',\n",
       " 'beastial',\n",
       " 'beastiality',\n",
       " 'bellend',\n",
       " 'bestial',\n",
       " 'bestiality',\n",
       " 'bi+ch',\n",
       " 'biatch',\n",
       " 'bimbos',\n",
       " 'birdlock',\n",
       " 'bitch',\n",
       " 'bitchass',\n",
       " 'bitcher',\n",
       " 'bitchers',\n",
       " 'bitches',\n",
       " 'bitchin',\n",
       " 'bitching',\n",
       " 'bitchtits',\n",
       " 'bitchy',\n",
       " 'black',\n",
       " 'bloody',\n",
       " 'blowjob',\n",
       " 'blowjobs',\n",
       " 'blumpkin',\n",
       " 'boiolas',\n",
       " 'bollock',\n",
       " 'bollocks',\n",
       " 'bollok',\n",
       " 'bollox',\n",
       " 'boner',\n",
       " 'boob',\n",
       " 'boobs',\n",
       " 'booobs',\n",
       " 'boooobs',\n",
       " 'booooobs',\n",
       " 'booooooobs',\n",
       " 'breasts',\n",
       " 'brotherfucker',\n",
       " 'buceta',\n",
       " 'bugger',\n",
       " 'bullshit',\n",
       " 'bum',\n",
       " 'bumblefuck',\n",
       " 'busty',\n",
       " 'butt',\n",
       " 'butt-pirate',\n",
       " 'buttfucka',\n",
       " 'buttfucker',\n",
       " 'butthole',\n",
       " 'buttmuch',\n",
       " 'buttplug',\n",
       " 'c0ck',\n",
       " 'c0cksucker',\n",
       " 'carpetmuncher',\n",
       " 'cawk',\n",
       " 'chink',\n",
       " 'choade',\n",
       " 'cipa',\n",
       " 'cl1t',\n",
       " 'clit',\n",
       " 'clitoris',\n",
       " 'clits',\n",
       " 'clusterfuck',\n",
       " 'cnut',\n",
       " 'cock',\n",
       " 'cock-sucker',\n",
       " 'cockface',\n",
       " 'cockhead',\n",
       " 'cockmunch',\n",
       " 'cockmuncher',\n",
       " 'cocks',\n",
       " 'cocksuck',\n",
       " 'cocksucked',\n",
       " 'cocksucker',\n",
       " 'cocksucking',\n",
       " 'cocksucks',\n",
       " 'cocksuka',\n",
       " 'cocksukka',\n",
       " 'cok',\n",
       " 'cokmuncher',\n",
       " 'coksucka',\n",
       " 'colored',\n",
       " 'coloured',\n",
       " 'coolie',\n",
       " 'coon',\n",
       " 'cornhole',\n",
       " 'cox',\n",
       " 'crap',\n",
       " 'cum',\n",
       " 'cumdump',\n",
       " 'cummer',\n",
       " 'cumming',\n",
       " 'cums',\n",
       " 'cumshot',\n",
       " 'cunilingus',\n",
       " 'cunillingus',\n",
       " 'cunnilingus',\n",
       " 'cunt',\n",
       " 'cunt-struck',\n",
       " 'cuntbag',\n",
       " 'cuntlick',\n",
       " 'cuntlicker',\n",
       " 'cuntlicking',\n",
       " 'cunts',\n",
       " 'cuntsicle',\n",
       " 'cyalis',\n",
       " 'cyberfuc',\n",
       " 'cyberfuck',\n",
       " 'cyberfucked',\n",
       " 'cyberfucker',\n",
       " 'cyberfuckers',\n",
       " 'cyberfucking',\n",
       " 'd1ck',\n",
       " 'dago',\n",
       " 'damn',\n",
       " 'dick',\n",
       " 'dickhead',\n",
       " 'dildo',\n",
       " 'dildos',\n",
       " 'dink',\n",
       " 'dinks',\n",
       " 'dirsa',\n",
       " 'dlck',\n",
       " 'dog-fucker',\n",
       " 'doggiestyle',\n",
       " 'doggin',\n",
       " 'dogging',\n",
       " 'donkeyribber',\n",
       " 'doosh',\n",
       " 'duche',\n",
       " 'dyke',\n",
       " 'ejaculate',\n",
       " 'ejaculated',\n",
       " 'ejaculates',\n",
       " 'ejaculating',\n",
       " 'ejaculatings',\n",
       " 'ejaculation',\n",
       " 'ejakulate',\n",
       " 'erotic',\n",
       " 'f4nny',\n",
       " 'f_u_c_k',\n",
       " 'facial',\n",
       " 'fag',\n",
       " 'fagging',\n",
       " 'faggitt',\n",
       " 'faggot',\n",
       " 'faggs',\n",
       " 'fagot',\n",
       " 'fagots',\n",
       " 'fags',\n",
       " 'fanny',\n",
       " 'fannyflaps',\n",
       " 'fannyfucker',\n",
       " 'fanyy',\n",
       " 'fatass',\n",
       " 'fcuk',\n",
       " 'fcuker',\n",
       " 'fcuking',\n",
       " 'feck',\n",
       " 'fecker',\n",
       " 'felching',\n",
       " 'fellate',\n",
       " 'fellatio',\n",
       " 'feringhee',\n",
       " 'fingerfuck',\n",
       " 'fingerfucked',\n",
       " 'fingerfucker',\n",
       " 'fingerfuckers',\n",
       " 'fingerfucking',\n",
       " 'fingerfucks',\n",
       " 'fistfuck',\n",
       " 'fistfucked',\n",
       " 'fistfucker',\n",
       " 'fistfuckers',\n",
       " 'fistfucking',\n",
       " 'fistfuckings',\n",
       " 'fistfucks',\n",
       " 'flange',\n",
       " 'fook',\n",
       " 'fooker',\n",
       " 'frog',\n",
       " 'fuck',\n",
       " 'fuck-ass',\n",
       " 'fuck-bitch',\n",
       " 'fucka',\n",
       " 'fucked',\n",
       " 'fucker',\n",
       " 'fuckers',\n",
       " 'fuckhead',\n",
       " 'fuckheads',\n",
       " 'fuckin',\n",
       " 'fuckings',\n",
       " 'fuckingshitmotherfucker',\n",
       " 'fuckme',\n",
       " 'fuckmeat',\n",
       " 'fucks',\n",
       " 'fucktoy',\n",
       " 'fuckwhit',\n",
       " 'fuckwit',\n",
       " 'fudgepacker',\n",
       " 'fuk',\n",
       " 'fuker',\n",
       " 'fukker',\n",
       " 'fukkin',\n",
       " 'fuks',\n",
       " 'fukwhit',\n",
       " 'fukwit',\n",
       " 'fux',\n",
       " 'fux0r',\n",
       " 'gang-bang',\n",
       " 'gangbang',\n",
       " 'gangbanged',\n",
       " 'gangbangs',\n",
       " 'gaylord',\n",
       " 'gaysex',\n",
       " 'goatse',\n",
       " 'god',\n",
       " 'god-dam',\n",
       " 'god-damned',\n",
       " 'goddamn',\n",
       " 'goddamned',\n",
       " 'gook',\n",
       " 'goy',\n",
       " 'gringo',\n",
       " 'gypsy',\n",
       " 'half-breed',\n",
       " 'half-caste',\n",
       " 'hardcoresex',\n",
       " 'hell',\n",
       " 'heshe',\n",
       " 'hoar',\n",
       " 'hoare',\n",
       " 'hoer',\n",
       " 'homo',\n",
       " 'homoerotic',\n",
       " 'honky',\n",
       " 'hore',\n",
       " 'horniest',\n",
       " 'horny',\n",
       " 'hotsex',\n",
       " 'idiot',\n",
       " 'jack-off',\n",
       " 'jackoff',\n",
       " 'jap',\n",
       " 'jerk',\n",
       " 'jerk-off',\n",
       " 'jism',\n",
       " 'jiz',\n",
       " 'jizm',\n",
       " 'jizz',\n",
       " 'jock',\n",
       " 'kaffir',\n",
       " 'kafir',\n",
       " 'kawk',\n",
       " 'knob',\n",
       " 'knobead',\n",
       " 'knobed',\n",
       " 'knobend',\n",
       " 'knobhead',\n",
       " 'knobjocky',\n",
       " 'knobjokey',\n",
       " 'kock',\n",
       " 'kondum',\n",
       " 'kondums',\n",
       " 'kum',\n",
       " 'kummer',\n",
       " 'kumming',\n",
       " 'kums',\n",
       " 'kunilingus',\n",
       " 'kwif',\n",
       " 'l3i+ch',\n",
       " 'l3itch',\n",
       " 'labia',\n",
       " 'lmao',\n",
       " 'lmfao',\n",
       " 'lust',\n",
       " 'lusting',\n",
       " 'm0f0',\n",
       " 'm0fo',\n",
       " 'm45terbate',\n",
       " 'ma5terb8',\n",
       " 'ma5terbate',\n",
       " 'mafugly',\n",
       " 'makwerekwere',\n",
       " 'malicious',\n",
       " 'masochist',\n",
       " 'master-bate',\n",
       " 'masterb8',\n",
       " 'masterbat*',\n",
       " 'masterbat3',\n",
       " 'masterbate',\n",
       " 'masterbation',\n",
       " 'masterbations',\n",
       " 'masturbate',\n",
       " 'mean',\n",
       " 'menacing',\n",
       " 'messy',\n",
       " 'mick',\n",
       " 'misshapen',\n",
       " 'missing',\n",
       " 'misunderstood',\n",
       " 'mo-fo',\n",
       " 'moan',\n",
       " 'mof0',\n",
       " 'mofo',\n",
       " 'moldy',\n",
       " 'monstrous',\n",
       " 'mothafuck',\n",
       " 'mothafucka',\n",
       " 'mothafuckas',\n",
       " 'mothafuckaz',\n",
       " 'mothafucked',\n",
       " 'mothafucker',\n",
       " 'mothafuckers',\n",
       " 'mothafuckin',\n",
       " 'mothafucking',\n",
       " 'mothafuckings',\n",
       " 'mothafucks',\n",
       " 'motherfuck',\n",
       " 'motherfucked',\n",
       " 'motherfucker',\n",
       " 'motherfuckers',\n",
       " 'motherfuckin',\n",
       " 'motherfucking',\n",
       " 'motherfuckings',\n",
       " 'motherfuckka',\n",
       " 'motherfucks',\n",
       " 'muff',\n",
       " 'mulatto',\n",
       " 'mutha',\n",
       " 'muthafecker',\n",
       " 'muthafuckker',\n",
       " 'muther',\n",
       " 'mutherfucker',\n",
       " 'n1gga',\n",
       " 'n1gger',\n",
       " 'naive',\n",
       " 'nasty',\n",
       " 'native',\n",
       " 'naughty',\n",
       " 'nazi',\n",
       " 'negate',\n",
       " 'negative',\n",
       " 'negress',\n",
       " 'negro',\n",
       " 'never',\n",
       " 'nigg3r',\n",
       " 'nigg4h',\n",
       " 'nigga',\n",
       " 'niggah',\n",
       " 'niggas',\n",
       " 'niggaz',\n",
       " 'nigger',\n",
       " 'niggers',\n",
       " 'no',\n",
       " 'nob',\n",
       " 'nobhead',\n",
       " 'nobjocky',\n",
       " 'nobjokey',\n",
       " 'nobody',\n",
       " 'non-white',\n",
       " 'nondescript',\n",
       " 'nonsense',\n",
       " 'not',\n",
       " 'noxious',\n",
       " 'numbnuts',\n",
       " 'nutsack',\n",
       " 'omg',\n",
       " 'orgasim',\n",
       " 'orgasims',\n",
       " 'orgasm',\n",
       " 'orgasms',\n",
       " 'oriental',\n",
       " 'p0rn',\n",
       " 'pakeha',\n",
       " 'paki',\n",
       " 'panooch',\n",
       " 'pawn',\n",
       " 'pecker',\n",
       " 'peckerhead',\n",
       " 'penis',\n",
       " 'penisbanger',\n",
       " 'penisfucker',\n",
       " 'penispuffer',\n",
       " 'phonesex',\n",
       " 'phuck',\n",
       " 'phuk',\n",
       " 'phuked',\n",
       " 'phuking',\n",
       " 'phukked',\n",
       " 'phukking',\n",
       " 'phuks',\n",
       " 'phuq',\n",
       " 'pickaninny',\n",
       " 'pigfucker',\n",
       " 'pimpis',\n",
       " 'piss',\n",
       " 'pissed',\n",
       " 'pisser',\n",
       " 'pissers',\n",
       " 'pisses',\n",
       " 'pissflaps',\n",
       " 'pissin',\n",
       " 'pissing',\n",
       " 'pissoff',\n",
       " 'polesmoker',\n",
       " 'pollock',\n",
       " 'pom',\n",
       " 'pommy',\n",
       " 'poon',\n",
       " 'poonani',\n",
       " 'poonany',\n",
       " 'poontang',\n",
       " 'poop',\n",
       " 'porchmonkey',\n",
       " 'porn',\n",
       " 'porno',\n",
       " 'pornography',\n",
       " 'pornos',\n",
       " 'prick',\n",
       " 'pricks',\n",
       " 'pron',\n",
       " 'pube',\n",
       " 'punanny',\n",
       " 'punta',\n",
       " 'pusse',\n",
       " 'pussi',\n",
       " 'pussies',\n",
       " 'pussy',\n",
       " 'pussylicking',\n",
       " 'pussys',\n",
       " 'puto',\n",
       " 'queaf',\n",
       " 'queer',\n",
       " 'rectum',\n",
       " 'redskin',\n",
       " 'retard',\n",
       " 'rimjaw',\n",
       " 'rimming',\n",
       " 's.o.b.',\n",
       " 's_h_i_t',\n",
       " 'sad',\n",
       " 'sadism',\n",
       " 'sadist',\n",
       " 'sandbar',\n",
       " 'savage',\n",
       " 'scare',\n",
       " 'scary',\n",
       " 'schlong',\n",
       " 'scream',\n",
       " 'screwing',\n",
       " 'scroat',\n",
       " 'scrote',\n",
       " 'scrotum',\n",
       " 'semen',\n",
       " 'severe',\n",
       " 'sex',\n",
       " 'sh!+',\n",
       " 'sh!t',\n",
       " 'sh1t',\n",
       " 'shag',\n",
       " 'shagger',\n",
       " 'shaggin',\n",
       " 'shagging',\n",
       " 'shemale',\n",
       " 'shi+',\n",
       " 'shit',\n",
       " 'shitdick',\n",
       " 'shite',\n",
       " 'shited',\n",
       " 'shitey',\n",
       " 'shitfuck',\n",
       " 'shitfull',\n",
       " 'shithead',\n",
       " 'shiting',\n",
       " 'shitings',\n",
       " 'shits',\n",
       " 'shitted',\n",
       " 'shitter',\n",
       " 'shitters',\n",
       " 'shitting',\n",
       " 'shittings',\n",
       " 'shitty',\n",
       " 'shocking',\n",
       " 'shoddy',\n",
       " 'sick',\n",
       " 'sickening',\n",
       " 'sinister',\n",
       " 'skank',\n",
       " 'slimy',\n",
       " 'slope',\n",
       " 'slut',\n",
       " 'sluts',\n",
       " 'smegma',\n",
       " 'smelly',\n",
       " 'smut',\n",
       " 'snatch',\n",
       " 'sobbing',\n",
       " 'son-of-a-bitch',\n",
       " 'sorry',\n",
       " 'spac',\n",
       " 'spade',\n",
       " 'spiteful',\n",
       " 'spunk',\n",
       " 'squaw',\n",
       " 'sticky',\n",
       " 'stinky',\n",
       " 'stormy',\n",
       " 'stressful',\n",
       " 'stuck',\n",
       " 'stupid',\n",
       " 'substandard',\n",
       " 'suck',\n",
       " 'suspect',\n",
       " 'suspicious',\n",
       " 't1tt1e5',\n",
       " 't1tties',\n",
       " 'teets',\n",
       " 'teez',\n",
       " 'testical',\n",
       " 'testicle',\n",
       " 'tit',\n",
       " 'titfuck',\n",
       " 'tits',\n",
       " 'titt',\n",
       " 'tittie5',\n",
       " 'tittiefucker',\n",
       " 'titties',\n",
       " 'tittyfuck',\n",
       " 'tittywank',\n",
       " 'titwank',\n",
       " 'tosser',\n",
       " 'turd',\n",
       " 'tw4t',\n",
       " 'twat',\n",
       " 'twathead',\n",
       " 'twatty',\n",
       " 'twunt',\n",
       " 'twunter',\n",
       " 'ugly',\n",
       " 'undermine',\n",
       " 'unfair',\n",
       " 'unfavorable',\n",
       " 'unhappy',\n",
       " 'unhealthy',\n",
       " 'unjust',\n",
       " 'unlucky',\n",
       " 'unpleasant',\n",
       " 'unsatisfactory',\n",
       " 'unsightly',\n",
       " 'untoward',\n",
       " 'unwanted',\n",
       " 'unwelcome',\n",
       " 'unwholesome',\n",
       " 'unwieldy',\n",
       " 'unwise',\n",
       " 'upset',\n",
       " 'v14gra',\n",
       " 'v1gra',\n",
       " 'vagina',\n",
       " 'viagra',\n",
       " 'vulva',\n",
       " 'w00se',\n",
       " 'wang',\n",
       " 'wank',\n",
       " 'wanker',\n",
       " 'wanky',\n",
       " 'waspy',\n",
       " 'wetback',\n",
       " 'whitey',\n",
       " 'whoar',\n",
       " 'whore',\n",
       " 'willies',\n",
       " 'willy',\n",
       " 'wog',\n",
       " 'wop',\n",
       " 'wtf',\n",
       " 'xrated',\n",
       " 'xxx',\n",
       " 'yid'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "d9cdb137a9864ff9a0bb32a5a9d0564d": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
